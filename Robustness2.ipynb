{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Station  Betweenness Centrality\n",
      "0             Clark St & Elm St                0.573311\n",
      "1         Dearborn St & Erie St                0.528830\n",
      "2     Desplaines St & Kinzie St                0.522241\n",
      "3       Clark St & Armitage Ave                0.495881\n",
      "4        Clark St & Schiller St                0.492586\n",
      "5     Ashland Ave & Division St                0.485997\n",
      "6   Dearborn Pkwy & Delaware Pl                0.482702\n",
      "7  Sheffield Ave & Waveland Ave                0.476112\n",
      "8        Clark St & Lincoln Ave                0.472817\n",
      "9     Larrabee St & Webster Ave                0.471170\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "# Set Pandas display options to ensure all columns are visible\n",
    "pd.set_option('display.max_columns', None)  # Display all columns\n",
    "pd.set_option('display.width', 1000)       # Increase display width\n",
    "pd.set_option('display.max_colwidth', None)  # Prevent column content from being truncated\n",
    "\n",
    "# Load the bike-sharing data\n",
    "file_path = 'zhong.csv'  # Replace with the actual file path\n",
    "bike_data = pd.read_csv(file_path)\n",
    "\n",
    "# Create a directed graph\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# Add edges to the graph based on start and end stations\n",
    "for _, row in bike_data.iterrows():\n",
    "    start_station = row['start_station_name']\n",
    "    end_station = row['end_station_name']\n",
    "    graph.add_edge(start_station, end_station)\n",
    "\n",
    "# Calculate the degree centrality of each station\n",
    "betweenness_centrality = nx.degree_centrality(graph)\n",
    "\n",
    "# Sort stations by centrality and extract the top 10\n",
    "top_10_stations = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# Convert the result to a DataFrame for better visualization\n",
    "top_10_df = pd.DataFrame(top_10_stations, columns=['Station', 'Betweenness Centrality'])\n",
    "\n",
    "# Print the top 10 important stations\n",
    "print(top_10_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Target_Station             Nearest_Station    Distance\n",
      "311              Clark St & Elm St           Wells St & Elm St  249.918245\n",
      "8            Dearborn St & Erie St       LaSalle Dr & Huron St   268.28195\n",
      "1357     Desplaines St & Kinzie St        Clinton St & Lake St  406.353032\n",
      "427        Clark St & Armitage Ave   Sedgwick St & Webster Ave  483.903805\n",
      "533         Clark St & Schiller St    Wells St & Evergreen Ave   309.54453\n",
      "1061     Ashland Ave & Division St  Ashland Ave & Blackhawk St   401.23225\n",
      "323    Dearborn Pkwy & Delaware Pl       State St & Pearson St  203.711362\n",
      "51    Sheffield Ave & Waveland Ave         Clark St & Grace St  419.581692\n",
      "89          Clark St & Lincoln Ave       Wells St & Concord Ln  399.943859\n",
      "962      Larrabee St & Webster Ave  Larrabee St & Armitage Ave  412.302791\n"
     ]
    }
   ],
   "source": [
    "from geopy.distance import geodesic\n",
    "\n",
    "# Add latitude and longitude to the important stations data\n",
    "top_10_df = top_10_df.merge(\n",
    "    bike_data[['start_station_name', 'start_lat', 'start_lng']].drop_duplicates(),\n",
    "    left_on='Station',\n",
    "    right_on='start_station_name',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Rename latitude and longitude columns\n",
    "top_10_df.rename(columns={'start_lat': 'lat', 'start_lng': 'lng'}, inplace=True)\n",
    "\n",
    "# Get latitude and longitude data for all stations\n",
    "all_stations = bike_data[['start_station_name', 'start_lat', 'start_lng']].drop_duplicates()\n",
    "all_stations.rename(columns={'start_station_name': 'Station', 'start_lat': 'lat', 'start_lng': 'lng'}, inplace=True)\n",
    "\n",
    "# Find the nearest station for each important station, ensuring no duplicates\n",
    "nearest_stations = []\n",
    "\n",
    "for _, row in top_10_df.iterrows():\n",
    "    target_station = row['Station']\n",
    "    target_coords = (row['lat'], row['lng'])\n",
    "\n",
    "    # Calculate distances to other stations, excluding the target station itself\n",
    "    filtered_stations = all_stations[all_stations['Station'] != target_station].copy()\n",
    "\n",
    "    # Compute the distance to each station\n",
    "    filtered_stations['Distance'] = filtered_stations.apply(\n",
    "        lambda x: geodesic(target_coords, (x['lat'], x['lng'])).meters, axis=1\n",
    "    )\n",
    "\n",
    "    # Find the nearest station, ensuring no duplicates\n",
    "    for i in range(len(filtered_stations)):\n",
    "        nearest = filtered_stations.nsmallest(i + 1, 'Distance').iloc[-1]\n",
    "        if nearest['Station'] not in top_10_df['Station'].values:\n",
    "            nearest['Target_Station'] = target_station\n",
    "            nearest_stations.append(nearest)\n",
    "            break\n",
    "\n",
    "# Combine results into a DataFrame\n",
    "nearest_stations_df = pd.concat(nearest_stations, axis=1).T  # Transpose to align data\n",
    "\n",
    "# Format the nearest stations data as a clean table\n",
    "cleaned_nearest_stations_df = nearest_stations_df[['Target_Station', 'Station', 'Distance']]\n",
    "\n",
    "# Rename columns\n",
    "cleaned_nearest_stations_df.columns = ['Target_Station', 'Nearest_Station', 'Distance']\n",
    "\n",
    "# Display the results\n",
    "print(cleaned_nearest_stations_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Station                hour  outflow  inflow  total_visits\n",
      "499     Clark St & Armitage Ave 2020-04-26 13:00:00     17.0    11.0          28.0\n",
      "2513  Larrabee St & Webster Ave 2020-04-19 15:00:00     11.0    14.0          25.0\n",
      "2112  Desplaines St & Kinzie St 2020-04-07 16:00:00     16.0     8.0          24.0\n",
      "1857      Dearborn St & Erie St 2020-04-11 15:00:00     13.0    11.0          24.0\n",
      "2576  Larrabee St & Webster Ave 2020-04-26 14:00:00     10.0    13.0          23.0\n",
      "...                         ...                 ...      ...     ...           ...\n",
      "3178     Clark St & Lincoln Ave 2020-04-12 10:00:00      0.0     3.0           3.0\n",
      "1090     Clark St & Lincoln Ave 2020-04-20 13:00:00      3.0     0.0           3.0\n",
      "1091     Clark St & Lincoln Ave 2020-04-20 14:00:00      2.0     1.0           3.0\n",
      "1098     Clark St & Lincoln Ave 2020-04-21 10:00:00      1.0     2.0           3.0\n",
      "1101     Clark St & Lincoln Ave 2020-04-21 17:00:00      2.0     1.0           3.0\n",
      "\n",
      "[1000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert time columns to datetime format and extract hourly intervals\n",
    "bike_data['start_time'] = pd.to_datetime(bike_data['start_time'])\n",
    "bike_data['end_time'] = pd.to_datetime(bike_data['end_time'])\n",
    "bike_data['hour'] = bike_data['start_time'].dt.floor('H')  # Round to the nearest hour\n",
    "\n",
    "# Count hourly outflows (departures)\n",
    "hourly_outflow = bike_data.groupby(['start_station_name', 'hour']).size().rename('outflow')\n",
    "\n",
    "# Count hourly inflows (arrivals)\n",
    "hourly_inflow = bike_data.groupby(['end_station_name', 'hour']).size().rename('inflow')\n",
    "\n",
    "# Combine inflow and outflow statistics\n",
    "hourly_stats = pd.concat([hourly_outflow, hourly_inflow], axis=1).fillna(0)\n",
    "\n",
    "# Calculate total visits as the sum of inflow and outflow\n",
    "hourly_stats['total_visits'] = hourly_stats['inflow'] + hourly_stats['outflow']\n",
    "\n",
    "# Retrieve the list of target and nearest stations (replace with actual lists from prior results)\n",
    "target_stations = cleaned_nearest_stations_df['Target_Station'].unique()\n",
    "\n",
    "# Filter statistics for target stations\n",
    "target_hourly_stats = hourly_stats.loc[hourly_stats.index.get_level_values(0).isin(target_stations)]\n",
    "\n",
    "# Reset index for easier handling\n",
    "target_hourly_stats = target_hourly_stats.reset_index()\n",
    "\n",
    "# Sort by 'total_visits' and group by 'level_0' (station names)\n",
    "top_100_target_visits = (\n",
    "    target_hourly_stats.sort_values(by='total_visits', ascending=False)  # Sort by total visits in descending order\n",
    "    .groupby('level_0', group_keys=False)  # Group by station name\n",
    "    .head(100)  # Keep the top 100 records for each station\n",
    ")\n",
    "\n",
    "# Rename 'level_0' to 'Station' for better clarity\n",
    "top_100_target_visits.rename(columns={'level_0': 'Station'}, inplace=True)\n",
    "formatted_top_100 = top_100_target_visits.reset_index(drop=True)  # Remove the default row index\n",
    "\n",
    "# Select necessary columns and reorder them\n",
    "formatted_top_100 = formatted_top_100[['Station', 'hour', 'inflow', 'outflow', 'total_visits']]\n",
    "\n",
    "# Format the time column as a string\n",
    "formatted_top_100['hour'] = formatted_top_100['hour'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Display results\n",
    "print(top_100_target_visits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Target_Station          Target_Time             Nearest_Station         Nearest_Time  Target_Total_Visits  Nearest_Total_Visits  Pair_Total_Visits\n",
      "0       Clark St & Armitage Ave  2020-04-26 13:00:00   Sedgwick St & Webster Ave  2020-04-26 13:00:00                 28.0                   8.0               36.0\n",
      "4     Larrabee St & Webster Ave  2020-04-26 14:00:00  Larrabee St & Armitage Ave  2020-04-26 14:00:00                 23.0                   8.0               31.0\n",
      "3         Dearborn St & Erie St  2020-04-11 15:00:00       LaSalle Dr & Huron St  2020-04-11 15:00:00                 24.0                   6.0               30.0\n",
      "2     Desplaines St & Kinzie St  2020-04-07 16:00:00        Clinton St & Lake St  2020-04-07 16:00:00                 24.0                   5.0               29.0\n",
      "6         Dearborn St & Erie St  2020-04-18 13:00:00       LaSalle Dr & Huron St  2020-04-18 13:00:00                 23.0                   6.0               29.0\n",
      "8  Sheffield Ave & Waveland Ave  2020-04-26 14:00:00         Clark St & Grace St  2020-04-26 14:00:00                 21.0                   7.0               28.0\n",
      "1     Larrabee St & Webster Ave  2020-04-19 15:00:00  Larrabee St & Armitage Ave  2020-04-19 15:00:00                 25.0                   2.0               27.0\n",
      "5        Clark St & Lincoln Ave  2020-04-19 15:00:00       Wells St & Concord Ln  2020-04-19 15:00:00                 23.0                   4.0               27.0\n",
      "7     Larrabee St & Webster Ave  2020-04-19 14:00:00  Larrabee St & Armitage Ave  2020-04-19 14:00:00                 23.0                   1.0               24.0\n",
      "9     Desplaines St & Kinzie St  2020-04-03 17:00:00        Clinton St & Lake St  2020-04-03 17:00:00                 21.0                   3.0               24.0\n"
     ]
    }
   ],
   "source": [
    "# Get the top 10 target stations and time periods\n",
    "top_10 = (\n",
    "    formatted_top_100.sort_values(by='total_visits', ascending=False)\n",
    "    .head(10)  # Retrieve the top 10 records\n",
    ")\n",
    "\n",
    "# Initialize the result storage\n",
    "results = []\n",
    "\n",
    "# Iterate through the top 10 records to find the nearest station and calculate total visits for the corresponding time period\n",
    "for _, row in top_10.iterrows():\n",
    "    target_station = row['Station']  # Target station\n",
    "    time_period = row['hour']  # Time period\n",
    "\n",
    "    # Find the corresponding nearest station\n",
    "    nearest_station = cleaned_nearest_stations_df[\n",
    "        cleaned_nearest_stations_df['Target_Station'] == target_station\n",
    "    ]['Nearest_Station'].values[0]\n",
    "\n",
    "    # Calculate total visits for the target station\n",
    "    target_total_visits = row['total_visits']\n",
    "\n",
    "    # Calculate total visits for the nearest station during the same time period\n",
    "    nearest_total_visits = hourly_stats.loc[(nearest_station, time_period), 'total_visits'] \\\n",
    "        if (nearest_station, time_period) in hourly_stats.index else 0\n",
    "\n",
    "    # Compute the sum of total visits for the station pair\n",
    "    pair_total_visits = target_total_visits + nearest_total_visits\n",
    "\n",
    "    # Add the result to the list\n",
    "    results.append({\n",
    "        'Target_Station': target_station,\n",
    "        'Target_Time': time_period,\n",
    "        'Nearest_Station': nearest_station,\n",
    "        'Nearest_Time': time_period,\n",
    "        'Target_Total_Visits': target_total_visits,\n",
    "        'Nearest_Total_Visits': nearest_total_visits,\n",
    "        'Pair_Total_Visits': pair_total_visits\n",
    "    })\n",
    "\n",
    "# Convert the results into a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort by Pair_Total_Visits in descending order\n",
    "results_df = results_df.sort_values(by='Pair_Total_Visits', ascending=False)\n",
    "\n",
    "# Output the results\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
